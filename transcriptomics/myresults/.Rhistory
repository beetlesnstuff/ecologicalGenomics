setwd("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/PopGenomics/results/")
library(ggplot2) # plotting
library(ggpubr) # plotting
library(RcppCNPy)
library(raster)
library(FactoMineR)
library(factoextra)
library(corrplot)
COV <- as.matrix(read.table("allRS_poly.cov")) # read in the genetic covariance matrix
PCA <- eigen(COV) # extract the principal components from the COV matrix
var <- round(PCA$values/sum(PCA$values),3)
var[1:3]
barplot(var,
xlab="Eigenvalues of the PCA",
ylab="Proportion of variance explained")
names <- read.table("allRS_bam.list")
names <- unlist(strsplit(basename(as.character(names[,1])), split = ".sorted.rmdup.bam"))
split = strsplit(names, "_")
pops <- data.frame(names[1:95], do.call(rbind, split[1:95]))
names(pops) = c("Ind", "Pop", "Row", "Col")
plot(PCA$vectors[,1:2],
col=as.factor(pops[,2]),
xlab="PC1",ylab="PC2",
main="Genetic PCA")
data=as.data.frame(PCA$vectors)
data=data[,c(1:3)]
data= cbind(data, pops)
cols=c("#377eB8","#EE9B00","#0A9396","#94D2BD","#FFCB69","#005f73","#E26D5C","#AE2012", "#6d597a", "#7EA16B","#d4e09b", "gray70")
ggscatter(data, x = "V1", y = "V2",
color = "Pop",
mean.point = TRUE,
star.plot = TRUE) +
theme_bw(base_size = 13, base_family = "Times") +
theme(panel.background = element_blank(),
legend.background = element_blank(),
panel.grid = element_blank(),
plot.background = element_blank(),
legend.text=element_text(size=rel(.7)),
axis.text = element_text(size=13),
legend.position = "bottom") +
labs(x = paste0("PC1: (",var[1]*100,"%)"), y = paste0("PC2: (",var[2]*100,"%)")) +
scale_color_manual(values=c(cols), name="Source population") +
guides(colour = guide_legend(nrow = 2))
q <- read.table("allRS_poly.admix.3.Q", sep=" ", header=F)
K=dim(q)[2] #Find the level of K modeled
## order according to population code
ord<-order(pops[,2])
# make the plot:
barplot(t(q)[,ord],
col=cols[1:K],
space=0,border=NA,
xlab="Populations",ylab="Admixture proportions",
main=paste0("Red spruce K=",K))
text(tapply(1:nrow(pops),pops[ord,2],mean),-0.05,unique(pops[ord,2]),xpd=T)
abline(v=cumsum(sapply(unique(pops[ord,2]),function(x){sum(pops[ord,2]==x)})),col=1,lwd=1.2)
list.files()
s<-npyLoad("allRS_poly.selection.npy")
# convert test statistic to p-value
pval <- as.data.frame(1-pchisq(s,1))
names(pval) = "p_PC1"
## read positions
p <- read.table("allRS_poly_mafs.sites",sep="\t",header=T, stringsAsFactors=T)
dim(p)
p_filtered = p[which(p$kept_sites==1),]
dim(p_filtered)
## make manhattan plot
plot(-log10(pval$p_PC1),
col=p_filtered$chromo,
xlab="Position",
ylab="-log10(p-value)",
main="Selection outliers: pcANGSD e=2 (K3)")
plot(-log10(pval$p_PC1[2e05:2.01e05]),
col=p_filtered$chromo,
xlab="Position",
ylab="-log10(p-value)",
main="Selection outliers: pcANGSD e=2 (K3)")
# get the contig with the lowest p-value for selection
sel_contig <- p_filtered[which(pval==min(pval$p_PC1)),c("chromo","position")]
sel_contig
# get all the outliers with p-values below some cutoff
cutoff=1e-4   # equals a 1 in 5,000 probability
outlier_contigs <- p_filtered[which(pval<cutoff),c("chromo","position")]
outlier_contigs
# how many outlier loci < the cutoff?
dim(outlier_contigs)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contigs$chromo))
outlier_contig <- outlier_contigs[which(outlier_contigs$position>0),]
outlier_contig
# how many outlier loci < the cutoff?
dim(outlier_contig)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contig$chromo))
write.table(unique(outlier_contigs$chromo),
"allRS_poly_PC1_outlier_contigs.txt",
sep="\t",
quote=F,
row.names=F,
col.names=F)
COV <- as.matrix(read.table("allRS_poly.cov"))
PCA <- eigen(COV)
p_filtered = p[which(p$kept_sites==1),]
dim(p_filtered)
dim(outlier_contig)[1]
setwd("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/PopGenomics/results/")
library(ggplot2) # plotting
library(ggpubr) # plotting
library(RcppCNPy)
library(raster)
library(FactoMineR)
library(factoextra)
library(corrplot)
COV <- as.matrix(read.table("allRS_poly.cov")) # read in the genetic covariance matrix
PCA <- eigen(COV) # extract the principal components from the COV matrix
var <- round(PCA$values/sum(PCA$values),3)
var[1:3]
barplot(var,
xlab="Eigenvalues of the PCA",
ylab="Proportion of variance explained")
names <- read.table("allRS_bam.list")
names <- unlist(strsplit(basename(as.character(names[,1])), split = ".sorted.rmdup.bam"))
split = strsplit(names, "_")
pops <- data.frame(names[1:95], do.call(rbind, split[1:95]))
names(pops) = c("Ind", "Pop", "Row", "Col")
plot(PCA$vectors[,1:2],
col=as.factor(pops[,2]),
xlab="PC1",ylab="PC2",
main="Genetic PCA")
data=as.data.frame(PCA$vectors)
data=data[,c(1:3)]
data= cbind(data, pops)
cols=c("#377eB8","#EE9B00","#0A9396","#94D2BD","#FFCB69","#005f73","#E26D5C","#AE2012", "#6d597a", "#7EA16B","#d4e09b", "gray70")
ggscatter(data, x = "V1", y = "V2",
color = "Pop",
mean.point = TRUE,
star.plot = TRUE) +
theme_bw(base_size = 13, base_family = "Times") +
theme(panel.background = element_blank(),
legend.background = element_blank(),
panel.grid = element_blank(),
plot.background = element_blank(),
legend.text=element_text(size=rel(.7)),
axis.text = element_text(size=13),
legend.position = "bottom") +
labs(x = paste0("PC1: (",var[1]*100,"%)"), y = paste0("PC2: (",var[2]*100,"%)")) +
scale_color_manual(values=c(cols), name="Source population") +
guides(colour = guide_legend(nrow = 2))
q <- read.table("allRS_poly.admix.3.Q", sep=" ", header=F)
K=dim(q)[2] #Find the level of K modeled
## order according to population code
ord<-order(pops[,2])
# make the plot:
barplot(t(q)[,ord],
col=cols[1:K],
space=0,border=NA,
xlab="Populations",ylab="Admixture proportions",
main=paste0("Red spruce K=",K))
text(tapply(1:nrow(pops),pops[ord,2],mean),-0.05,unique(pops[ord,2]),xpd=T)
abline(v=cumsum(sapply(unique(pops[ord,2]),function(x){sum(pops[ord,2]==x)})),col=1,lwd=1.2)
list.files()
s<-npyLoad("allRS_poly.selection.npy")
# convert test statistic to p-value
pval <- as.data.frame(1-pchisq(s,1))
names(pval) = "p_PC1"
## read positions
p <- read.table("allRS_poly_mafs.sites",sep="\t",header=T, stringsAsFactors=T)
dim(p)
p_filtered = p[which(p$kept_sites==1),]
dim(p_filtered)
# get the contig with the lowest p-value for selection
sel_contig <- p_filtered[which(pval==min(pval$p_PC1)),c("chromo","position")]
sel_contig
# get all the outliers with p-values below some cutoff
cutoff=1e-4   # equals a 1 in 5,000 probability
outlier_contig <- outlier_contigs[which(outlier_contigs$position>0),]
outlier_contigs <- p_filtered[which(pval<cutoff),c("chromo","position")]
outlier_contigs
outlier_contig <- outlier_contigs[which(outlier_contigs$position>0),]
outlier_contig
dim(outlier_contig)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contig$chromo))
K=dim(q)[3] #Find the level of K modeled
## order according to population code
ord<-order(pops[,2])
# make the plot:
barplot(t(q)[,ord],
col=cols[1:K],
space=0,border=NA,
xlab="Populations",ylab="Admixture proportions",
main=paste0("Red spruce K=",K))
text(tapply(1:nrow(pops),pops[ord,2],mean),-0.05,unique(pops[ord,2]),xpd=T)
abline(v=cumsum(sapply(unique(pops[ord,2]),function(x){sum(pops[ord,2]==x)})),col=1,lwd=1.2)
list.files()
s<-npyLoad("allRS_poly.selection.npy")
# convert test statistic to p-value
pval <- as.data.frame(1-pchisq(s,1))
names(pval) = "p_PC1"
## read positions
p <- read.table("allRS_poly_mafs.sites",sep="\t",header=T, stringsAsFactors=T)
dim(p)
p_filtered = p[which(p$kept_sites==1),]
dim(p_filtered)
## make manhattan plot
plot(-log10(pval$p_PC1),
col=p_filtered$chromo,
xlab="Position",
ylab="-log10(p-value)",
main="Selection outliers: pcANGSD e=2 (K3)")
# get the contig with the lowest p-value for selection
sel_contig <- p_filtered[which(pval==min(pval$p_PC1)),c("chromo","position")]
sel_contig
# get all the outliers with p-values below some cutoff
cutoff=1e-4   # equals a 1 in 5,000 probability
outlier_contigs <- p_filtered[which(pval<cutoff),c("chromo","position")]
outlier_contigs
outlier_contig <- outlier_contigs[which(outlier_contigs$position>0),]
outlier_contig
dim(outlier_contig)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contig$chromo))
# get all the outliers with p-values below some cutoff
cutoff=1e-3   # equals a 1 in 5,000 probability
outlier_contigs <- p_filtered[which(pval<cutoff),c("chromo","position")]
outlier_contigs
outlier_contig <- outlier_contigs[which(outlier_contigs$position>0),]
outlier_contig
dim(outlier_contig)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contig$chromo))
# get the contig with the lowest p-value for selection
sel_contig <- p_filtered[which(pval==min(pval$p_PC1)),c("chromo","position")]
sel_contig
# get all the outliers with p-values below some cutoff
cutoff=1e-3   # equals a 1 in 5,000 probability
outlier_contigs <- p_filtered[which(pval<cutoff),c("chromo","position")]
outlier_contigs
dim(outlier_contigs)[1]
dim(outlier_contigs)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contigs$chromo))
write.table(unique(outlier_contigs$chromo),
"allRS_poly_PC1_outlier_contigs.txt",
sep="\t",
quote=F,
row.names=F,
col.names=F)
COV <- as.matrix(read.table("allRS_poly.cov"))
PCA <- eigen(COV)
data=as.data.frame(PCA$vectors)
data=data[,c(1:2)] # the second number here is the number of PC axes you want to keep
write.table(data,
"allRS_poly_genPC1_2.txt",
sep="\t",
quote=F,
row.names=F,
col.names=F)
bio <- getData("worldclim",var="bio",res=10)
coords <- read.csv("https://www.uvm.edu/~kellrlab/forClass/colebrookSampleMetaData.csv", header=T)
names <- read.table("allRS_bam.list")
names <- unlist(strsplit(basename(as.character(names[,1])), split = ".sorted.rmdup.bam"))
split = strsplit(names, "_")
pops <- data.frame(names[1:95], do.call(rbind, split[1:95]))
names(pops) = c("Ind", "Pop", "Row", "Col")
angsd_coords <- merge(pops, coords, by.x="Ind", by.y="Tree")
points <- SpatialPoints(angsd_coords[c("Longitude","Latitude")])
clim <- extract(bio,points)
angsd_coords_clim <- cbind.data.frame(angsd_coords,clim)
str(angsd_coords_clim)
clim_PCA = PCA(angsd_coords_clim[,15:33], graph=T)
fviz_eig(clim_PCA)
fviz_pca_biplot(clim_PCA,
geom.ind="point",
col.ind = angsd_coords_clim$Latitude,
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
title="Climate PCA (Bioclim)",
legend.title="Latitude")
dimdesc(clim_PCA)[1:2]
write.table(scale(angsd_coords_clim["bio12"]),
"allRS_bio12.txt",
sep="\t",
quote=F,
row.names = F,
col.names=F)
write.table(scale(angsd_coords_clim["bio10"]),
"allRS_bio10.txt",
sep="\t",
quote=F,
row.names = F,
col.names=F)
# how many unique contigs harbor outlier loci?
length(unique(outlier_contigs$chromo))
# how many unique contigs harbor outlier loci?
length(unique(outlier_contigs$chromo))
dim(outlier_contigs)[1]
# how many unique contigs harbor outlier loci?
length(unique(outlier_contigs$chromo))
write.table(scale(angsd_coords_clim["bio12"]),
"allRS_bio12.txt",
sep="\t",
quote=F,
row.names = F,
col.names=F)
write.table(scale(angsd_coords_clim["bio10"]),
"allRS_bio10.txt",
sep="\t",
quote=F,
row.names = F,
col.names=F)
write.table(data,
"allRS_poly_genPC1_2.txt",
sep="\t",
quote=F,
row.names=F,
col.names=F)
write.table(data,
"allRS_poly_genPC1_2.txt",
sep="\t",
quote=F,
row.names=F,
col.names=F)
outliers_PC2 <- p_filtered[which(pval$p_PC2<cutoff),c("chromo","position")]
dim(outliers_PC1)[1]
sel_contig <- p_filtered[which(pval==min(pval$p_PC2)),c("chromo","position")]
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("DESeq2")
setwd("~/github/hudsonica")
setwd("~/github/hudsonica")
if (!require("BiocManager", quietly = TRUE))
setwd("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/transcriptomics/myresults//")
# Import the counts matrix
countsTable <- read.table("data/salmon.isoform.counts.matrix", header=TRUE, row.names=1)
# Import the counts matrix
countsTable <- read.table("myresults/salmon.isoform.counts.matrix", header=TRUE, row.names=1)
# Import the counts matrix
countsTable <- read.table("salmon.isoform.counts.matrix", header=TRUE, row.names=1)
# Import the counts matrix
countsTable <- read.table("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/transcriptomics/myresults/salmon.isoform.counts.matrix", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
#import the sample discription table
conds <- read.delim("ahud_samples_R.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
setwd("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/transcriptomics/myresults/")
# Import the counts matrix
countsTable <- read.table("/Users/alexanderkissonergis/Documents/GitHub/ecologicalGenomics/transcriptomics/myresults/salmon.isoform.counts.matrix", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # bc DESeq2 doesn't like decimals (and Salmon outputs data with decimals)
head(countsTableRound)
#import the sample discription table
conds <- read.delim("ahud_samples_R.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1)
head(conds)
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,20000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound)) # [1] 11930.81 - tonsa, 6076.078 - hudsonica genes, 2269 - hudsonica isoform
median(rowSums(countsTableRound)) # [1] 2226 - tonsa, 582 - hudsonica, 109
apply(countsTableRound,2,mean) # 2 in the apply function does the action across columns
apply(countsTableRound,1,mean) # 1 in the apply function does the action across rows
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,120000),breaks=10000)
# Let's see how many reads we have from each sample
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,20000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound)) # [1] 11930.81 - tonsa, 6076.078 - hudsonica genes, 2269 - hudsonica isoform
median(rowSums(countsTableRound)) # [1] 2226 - tonsa, 582 - hudsonica, 109
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,20000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
barplot(colSums(countsTableRound), names.arg=colnames(countsTableRound),cex.names=0.5, las=3,ylim=c(0,21000000))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd=2)
# the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound)) # [1] 11930.81 - tonsa, 6076.078 - hudsonica genes, 2269 - hudsonica isoform
median(rowSums(countsTableRound)) # [1] 2226 - tonsa, 582 - hudsonica, 109
apply(countsTableRound,2,mean) # 2 in the apply function does the action across columns
apply(countsTableRound,1,mean) # 1 in the apply function does the action across rows
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,120000),breaks=10000)
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,190000),breaks=10000)
hist(apply(countsTableRound,1,mean),xlim=c(0,1000), ylim=c(0,300000),breaks=10000)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=conds,
design= ~ generation + treatment)
library(DESeq2)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData=conds,
design= ~ generation + treatment)
dim(dds)
dds <- dds[rowSums(counts(dds) >= 30) >= 28,]
nrow(dds)
# Run the DESeq model to test for differential gene expression
dds <- DESeq(dds)
# List the results you've generated
resultsNames(dds)
